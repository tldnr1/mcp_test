# multi_client.py
import asyncio
from dotenv import load_dotenv

# Multi MCP í´ë¼ì´ì–¸íŠ¸ ë° ì—ì´ì „íŠ¸ ìƒì„± ê´€ë ¨ ëª¨ë“ˆ
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI

# .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ˆê¸°í™”
model = ChatOpenAI(model="gpt-4o")

async def main():
    # ì—¬ëŸ¬ MCP ì„œë²„ì˜ ì„¤ì •ì„ êµ¬ì„±
    async with MultiServerMCPClient({
        "math": {
            "command": "python",  # ë‚´ë¶€ì ìœ¼ë¡œ subprocessë¡œ ì‹¤í–‰
            "args": ["math_server.py"],  # stdio ë°©ì‹ ì‹¤í–‰
            "transport": "stdio",
        },
        "weather": {
            "url": "http://localhost:8000/sse",  # SSEë¡œ í†µì‹ 
            "transport": "sse",
        }
    }) as client:
        # MCPì—ì„œ ë¡œë“œí•œ tool ëª©ë¡ì„ í¬í•¨í•˜ëŠ” LangGraph agent ìƒì„±
        agent = create_react_agent(model, client.get_tools())

        # 1. ìˆ˜í•™ ì§ˆë¬¸ â†’ math MCP ì‚¬ìš©
        math_result = await agent.ainvoke({"messages": "what's (4 + 6) x 10?"})
        print("ğŸ“ Math result:\n", math_result)

        # 2. ë‚ ì”¨ ì§ˆë¬¸ â†’ weather MCP ì‚¬ìš©
        weather_result = await agent.ainvoke({"messages": "what's the weather in Korea?"})
        print("ğŸŒ¦ï¸ Weather result:\n", weather_result)

if __name__ == "__main__":
    asyncio.run(main())
